{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAQs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Are the codes used for training word2vec on each framework the most optimized(in terms of memory usage and training time) ones?**\n",
    "\n",
    "The aim of this benchmark is to compare the most popularly and widely used codes for training word2vec and not necessarily the most optimized one. The code for training on each framework have been picked (and trivially modified in some cases) from the examples given in their respective offical github repositories. The code has also been reviewed by leading developers in each framework. Below are a few gitter chat snapshots and links for the same:\n",
    "\n",
    "**DL4J**\n",
    "![dl4j](FAQ-images/dl4j-1.bmp)\n",
    "![dl4j](FAQ-images/dl4j-2.bmp)\n",
    "\n",
    "\n",
    "**Tensorflow**\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/issues/13048\n",
    "\n",
    "https://stackoverflow.com/questions/46227847/tensorflow-word2vec-gpu-slower-than-cpu\n",
    "\n",
    "https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/pkRRdxqThCI\n",
    "\n",
    "**Original C Code**\n",
    "\n",
    "This does not need any review as such since it only requires running an executable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Why isn't it possible to run word2vec on GPU using DL4J?**\n",
    "\n",
    "![dl4j-noGPU](FAQ-images/dl4j-gpu.bmp)\n",
    "\n",
    "TL;DR : JVM Garbage Collector kills performance making it difficult to exploit GPU to speed up training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is tensorflow taking longer to run on GPU compared to CPU?\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/issues/13048#issuecomment-329893271\n",
    "\n",
    "Here is a link to another blog which discusses and analyses why training word2vec on cpu is faster than gpu using keras with tensorflow/theano backends.\n",
    "\n",
    "https://rare-technologies.com/gensim-word2vec-on-cpu-faster-than-word2veckeras-on-gpu-incubator-student-blog/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why doesn't the vocabulary size for DL4J match the vocabulary size for other frameworks?\n",
    "\n",
    "The culprint here is Java, which is notorious for having character encoding issues. Text corpora with non utf encoding can cause two different words with a few unrecognizable characters to map to the same string in the vocabulary. This causes dl4j to have a slightly smaller dictionary than the other frameworks.\n",
    "\n",
    "![dl4j-vocab-1](FAQ-images/dl4j-vocab-1.jpg)\n",
    "\n",
    "![dl4j-vocab-2](FAQ-images/dl4j-vocab-2.jpg)\n",
    "\n",
    "![dl4j-vocab-3](FAQ-images/dl4j-vocab-3.bmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Why doesn't gensim utilize all cpu cores when training on large machines?\n",
    "\n",
    "This is a known limitation of the current word2vec implementation. Complete utilization of all cpu cores is limited due to two factors:\n",
    "i.  A single corpus reader thread and \n",
    "ii. Python GIL(Global Interpreter Lock) contention between threads \n",
    "\n",
    "> \"Because large parts of the code are still subject to the Python GIL, saturating all cores is unattainable, and indeedtrying to use more workers can decrease total throughput through more contention\".\n",
    "\n",
    "    \n",
    "> \"There's still the issue of the Python GIL, which means the pure-Python portions of the process contend with each other, and beyond some count of workers, such contention can mean more workers will stop helping and start hurting overall throughput\". \n",
    "\n",
    "https://github.com/RaRe-Technologies/gensim/issues/1617#issuecomment-335367748\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
